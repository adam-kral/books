{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# disable tf warnings\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')\n",
    "import tensorflow_recommenders as tfrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from dataset import read_bx_csv\n",
    "\n",
    "data_root = Path('data/BX-CSV-Dump')\n",
    "users = read_bx_csv(data_root / 'BX-Users.csv')\n",
    "books = read_bx_csv(data_root / 'BX-Books.csv')\n",
    "ratings = read_bx_csv(data_root / 'BX-Book-Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ISBN\n0000913154    1\n0812515560    1\n0812514440    1\n0812514459    1\n0812514475    1\n0812514483    1\n0812515110    1\n0812515129    1\n0812515161    1\n0812515218    1\nName: ISBN, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.ISBN.groupby(books.ISBN).count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ISBN                   0\nBook-Title             0\nBook-Author            2\nYear-Of-Publication    0\nPublisher              2\nImage-URL-S            0\nImage-URL-M            0\nImage-URL-L            0\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get statistic of NA values values in books\n",
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "User-ID          0\nLocation         0\nAge         110762\ndtype: int64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get statistic of NA values values in users\n",
    "users.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "    User-ID                            Location   Age\n0         1                  nyc, new york, usa   NaN\n1         2           stockton, california, usa  18.0\n2         3     moscow, yukon territory, russia   NaN\n3         4           porto, v.n.gaia, portugal  17.0\n4         5  farnborough, hants, united kingdom   NaN\n..      ...                                 ...   ...\n95       96           helsinki, alaska, finland   NaN\n96       97    mechanicsburg, pennsylvania, usa   NaN\n97       98     pukekohe, auckland, new zealand  19.0\n98       99            franktown, colorado, usa  42.0\n99      100                  madrid, n/a, spain  44.0\n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User-ID</th>\n      <th>Location</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>nyc, new york, usa</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>stockton, california, usa</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>moscow, yukon territory, russia</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>porto, v.n.gaia, portugal</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>farnborough, hants, united kingdom</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>96</td>\n      <td>helsinki, alaska, finland</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>97</td>\n      <td>mechanicsburg, pennsylvania, usa</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>98</td>\n      <td>pukekohe, auckland, new zealand</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>99</td>\n      <td>franktown, colorado, usa</td>\n      <td>42.0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>100</td>\n      <td>madrid, n/a, spain</td>\n      <td>44.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(100)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              ISBN                                         Book-Title  \\\n118038  0751352497                           A+ Quiz Masters:01 Earth   \n187700  9627982032  The Credit Suisse Guide to Managing Your Perso...   \n\n       Book-Author  Year-Of-Publication                       Publisher  \\\n118038         NaN                 1999              Dorling Kindersley   \n187700         NaN                 1995  Edinburgh Financial Publishing   \n\n                                              Image-URL-S  \\\n118038  http://images.amazon.com/images/P/0751352497.0...   \n187700  http://images.amazon.com/images/P/9627982032.0...   \n\n                                              Image-URL-M  \\\n118038  http://images.amazon.com/images/P/0751352497.0...   \n187700  http://images.amazon.com/images/P/9627982032.0...   \n\n                                              Image-URL-L  \n118038  http://images.amazon.com/images/P/0751352497.0...  \n187700  http://images.amazon.com/images/P/9627982032.0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ISBN</th>\n      <th>Book-Title</th>\n      <th>Book-Author</th>\n      <th>Year-Of-Publication</th>\n      <th>Publisher</th>\n      <th>Image-URL-S</th>\n      <th>Image-URL-M</th>\n      <th>Image-URL-L</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>118038</th>\n      <td>0751352497</td>\n      <td>A+ Quiz Masters:01 Earth</td>\n      <td>NaN</td>\n      <td>1999</td>\n      <td>Dorling Kindersley</td>\n      <td>http://images.amazon.com/images/P/0751352497.0...</td>\n      <td>http://images.amazon.com/images/P/0751352497.0...</td>\n      <td>http://images.amazon.com/images/P/0751352497.0...</td>\n    </tr>\n    <tr>\n      <th>187700</th>\n      <td>9627982032</td>\n      <td>The Credit Suisse Guide to Managing Your Perso...</td>\n      <td>NaN</td>\n      <td>1995</td>\n      <td>Edinburgh Financial Publishing</td>\n      <td>http://images.amazon.com/images/P/9627982032.0...</td>\n      <td>http://images.amazon.com/images/P/9627982032.0...</td>\n      <td>http://images.amazon.com/images/P/9627982032.0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[books['Book-Author'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ''\n",
    "books[books['ISBN'] == '']['ISBN'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ratings_with_title = ratings.merge(books[['Book-Title', 'ISBN']], on='ISBN')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import filter_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fltrd_ratings_with_title = filter_ratings(ratings_with_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   User-ID            Book-Title  Book-Rating\n0     2313  Flesh Tones: A Novel            5\n1     6543  Flesh Tones: A Novel            0\n2     8680  Flesh Tones: A Novel            5\n3    10314  Flesh Tones: A Novel            9\n4    23768  Flesh Tones: A Novel            0\n5    28523  Flesh Tones: A Novel            0\n6    56157  Flesh Tones: A Novel            0\n7    77480  Flesh Tones: A Novel            8\n8    77940  Flesh Tones: A Novel            0\n9    81977  Flesh Tones: A Novel            0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User-ID</th>\n      <th>Book-Title</th>\n      <th>Book-Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2313</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6543</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8680</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10314</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23768</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>28523</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>56157</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>77480</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>77940</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>81977</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fltrd_ratings_with_title.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "fltrd_ratings_with_title_200 = filter_ratings(ratings_with_title, user_ratings_max_count=200)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implicit: 208347 explicit: 111149\n",
      "implicit: 132241 explicit: 91929\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of rating values\n",
    "\n",
    "fltrd_ratings_with_title.hist(column='Book-Rating', bins=11)\n",
    "implicit_count = sum(fltrd_ratings_with_title['Book-Rating'] == 0)\n",
    "print('implicit:', implicit_count, 'explicit:', len(fltrd_ratings_with_title) - implicit_count)\n",
    "\n",
    "fltrd_ratings_with_title_200.hist(column='Book-Rating', bins=11)\n",
    "implicit_count = sum(fltrd_ratings_with_title_200['Book-Rating'] == 0)\n",
    "print('implicit:', implicit_count, 'explicit:', len(fltrd_ratings_with_title_200) - implicit_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from dataset import squash_user_ids\n",
    "new_to_orig_user_id, orig_to_new_user_id = squash_user_ids(fltrd_ratings_with_title)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11206\n"
     ]
    }
   ],
   "source": [
    "print(len(new_to_orig_user_id))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# convert to tf dataset\n",
    "ds_ratings_with_title = tf.data.Dataset.from_tensor_slices(dict(fltrd_ratings_with_title[['Book-Title', 'User-ID']]))\n",
    "ds_book_titles = tf.data.Dataset.from_tensor_slices(fltrd_ratings_with_title['Book-Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create stringlookup vocabs\n",
    "# not needed, already int\n",
    "# user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "# user_ids_vocabulary.adapt(ratings['User-ID'])\n",
    "\n",
    "book_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "book_titles_vocabulary.adapt(ds_book_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6485 271379\n",
      "319496 1149780\n"
     ]
    }
   ],
   "source": [
    "print(len(ds_book_titles), len(books))\n",
    "print(len(ds_ratings_with_title), len(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "class BookBXModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      book_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.book_model = book_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(features['User-ID'])\n",
    "    book_embeddings = self.book_model(features['Book-Title'])\n",
    "\n",
    "    return self.task(user_embeddings, book_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Define user and movie models.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m user_model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mSequential([\n\u001B[0;32m----> 3\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mEmbedding(\u001B[38;5;28mlen\u001B[39m(\u001B[43munique_users\u001B[49m), \u001B[38;5;241m64\u001B[39m)\n\u001B[1;32m      4\u001B[0m ])\n\u001B[1;32m      6\u001B[0m book_model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mSequential([\n\u001B[1;32m      7\u001B[0m     book_titles_vocabulary,\n\u001B[1;32m      8\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mEmbedding(book_titles_vocabulary\u001B[38;5;241m.\u001B[39mvocabulary_size(), \u001B[38;5;241m64\u001B[39m),\n\u001B[1;32m      9\u001B[0m ])\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Define your objectives.\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# loss use the default, but with reduction to mean (so we can compare loss between\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'unique_users' is not defined"
     ]
    }
   ],
   "source": [
    "# Define user and movie models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(unique_users), 64)\n",
    "])\n",
    "\n",
    "book_model = tf.keras.Sequential([\n",
    "    book_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(book_titles_vocabulary.vocabulary_size(), 64),\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "# loss use the default, but with reduction to mean (so we can compare loss between\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(candidates=ds_book_titles.batch(128).map(book_model)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "79/79 [==============================] - 231s 3s/step - factorized_top_k/top_1_categorical_accuracy: 4.3819e-05 - factorized_top_k/top_5_categorical_accuracy: 5.8530e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0013 - factorized_top_k/top_50_categorical_accuracy: 0.0076 - factorized_top_k/top_100_categorical_accuracy: 0.0152 - loss: 33218.2935 - regularization_loss: 0.0000e+00 - total_loss: 33218.2935\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 254s 3s/step - factorized_top_k/top_1_categorical_accuracy: 1.2833e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0018 - factorized_top_k/top_10_categorical_accuracy: 0.0036 - factorized_top_k/top_50_categorical_accuracy: 0.0175 - factorized_top_k/top_100_categorical_accuracy: 0.0323 - loss: 33208.2987 - regularization_loss: 0.0000e+00 - total_loss: 33208.2987\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 216s 3s/step - factorized_top_k/top_1_categorical_accuracy: 4.7575e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0089 - factorized_top_k/top_50_categorical_accuracy: 0.0346 - factorized_top_k/top_100_categorical_accuracy: 0.0607 - loss: 33196.9451 - regularization_loss: 0.0000e+00 - total_loss: 33196.9451\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_recommenders.layers' has no attribute 'ann'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(da_ratings_with_title\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m4096\u001B[39m), epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Use brute-force search to set up retrieval using the trained representations.\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[43mtfrs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mann\u001B[49m\u001B[38;5;241m.\u001B[39mBruteForce(model\u001B[38;5;241m.\u001B[39muser_model)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# index.index(books.batch(100).map(model.book_model), books)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m index\u001B[38;5;241m.\u001B[39mindex_from_dataset(\n\u001B[1;32m     12\u001B[0m     tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mzip(da_book_titles\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m100\u001B[39m), da_book_titles\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m100\u001B[39m)\u001B[38;5;241m.\u001B[39mmap(model\u001B[38;5;241m.\u001B[39mbook_model))\n\u001B[1;32m     13\u001B[0m )\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow_recommenders.layers' has no attribute 'ann'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a retrieval model.\n",
    "model = BookBXModel(user_model, book_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))  # why not adam?\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ds_ratings_with_title.batch(4096), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommendations for user 0: [b'Rising Sun' b'Bel Canto: A Novel' b'Driving Force']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# index.index(books.batch(100).map(model.book_model), books)\n",
    "index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((ds_book_titles.batch(100), ds_book_titles.batch(100).map(model.book_model)))\n",
    "    # tf.data.Dataset.zip(ds_book_titles.batch(100), ds_book_titles.batch(100).map(model.book_model))\n",
    ")\n",
    "\n",
    "# Get some recommendations.\n",
    "_, titles = index(np.array([0]))\n",
    "print(f\"Top 3 recommendations for user 0: {titles[0, :3]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "79/79 [==============================] - 174s 2s/step - factorized_top_k/top_1_categorical_accuracy: 2.8795e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0026 - factorized_top_k/top_10_categorical_accuracy: 0.0053 - factorized_top_k/top_50_categorical_accuracy: 0.0222 - factorized_top_k/top_100_categorical_accuracy: 0.0387 - loss: 33142.7286 - regularization_loss: 0.0000e+00 - total_loss: 33142.7286\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 239s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0194 - factorized_top_k/top_10_categorical_accuracy: 0.0311 - factorized_top_k/top_50_categorical_accuracy: 0.0746 - factorized_top_k/top_100_categorical_accuracy: 0.1078 - loss: 32066.3732 - regularization_loss: 0.0000e+00 - total_loss: 32066.3732\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 170s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0058 - factorized_top_k/top_5_categorical_accuracy: 0.0320 - factorized_top_k/top_10_categorical_accuracy: 0.0538 - factorized_top_k/top_50_categorical_accuracy: 0.1485 - factorized_top_k/top_100_categorical_accuracy: 0.2203 - loss: 30034.3620 - regularization_loss: 0.0000e+00 - total_loss: 30034.3620\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1378cf050>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a retrieval model.\n",
    "model = BookBXModel(user_model, book_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01))  # why not adam?\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ds_ratings_with_title.batch(4096), epochs=3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "79/79 [==============================] - 160s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0058 - factorized_top_k/top_5_categorical_accuracy: 0.0267 - factorized_top_k/top_10_categorical_accuracy: 0.0418 - factorized_top_k/top_50_categorical_accuracy: 0.1079 - factorized_top_k/top_100_categorical_accuracy: 0.1626 - loss: 29552.6832 - regularization_loss: 0.0000e+00 - total_loss: 29552.6832\n",
      "Epoch 2/15\n",
      "79/79 [==============================] - 159s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0089 - factorized_top_k/top_5_categorical_accuracy: 0.0377 - factorized_top_k/top_10_categorical_accuracy: 0.0601 - factorized_top_k/top_50_categorical_accuracy: 0.1509 - factorized_top_k/top_100_categorical_accuracy: 0.2154 - loss: 29871.5131 - regularization_loss: 0.0000e+00 - total_loss: 29871.5131\n",
      "Epoch 3/15\n",
      "79/79 [==============================] - 161s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0123 - factorized_top_k/top_5_categorical_accuracy: 0.0435 - factorized_top_k/top_10_categorical_accuracy: 0.0667 - factorized_top_k/top_50_categorical_accuracy: 0.1558 - factorized_top_k/top_100_categorical_accuracy: 0.2173 - loss: 30357.5364 - regularization_loss: 0.0000e+00 - total_loss: 30357.5364\n",
      "Epoch 4/15\n",
      "79/79 [==============================] - 161s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0213 - factorized_top_k/top_5_categorical_accuracy: 0.0670 - factorized_top_k/top_10_categorical_accuracy: 0.0968 - factorized_top_k/top_50_categorical_accuracy: 0.2013 - factorized_top_k/top_100_categorical_accuracy: 0.2700 - loss: 29085.3245 - regularization_loss: 0.0000e+00 - total_loss: 29085.3245\n",
      "Epoch 5/15\n",
      "79/79 [==============================] - 157s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0211 - factorized_top_k/top_5_categorical_accuracy: 0.0652 - factorized_top_k/top_10_categorical_accuracy: 0.0957 - factorized_top_k/top_50_categorical_accuracy: 0.2095 - factorized_top_k/top_100_categorical_accuracy: 0.2847 - loss: 28139.9444 - regularization_loss: 0.0000e+00 - total_loss: 28139.9444\n",
      "Epoch 6/15\n",
      "79/79 [==============================] - 157s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0238 - factorized_top_k/top_5_categorical_accuracy: 0.0768 - factorized_top_k/top_10_categorical_accuracy: 0.1134 - factorized_top_k/top_50_categorical_accuracy: 0.2450 - factorized_top_k/top_100_categorical_accuracy: 0.3280 - loss: 27003.5114 - regularization_loss: 0.0000e+00 - total_loss: 27003.5114\n",
      "Epoch 7/15\n",
      "79/79 [==============================] - 155s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0214 - factorized_top_k/top_5_categorical_accuracy: 0.0791 - factorized_top_k/top_10_categorical_accuracy: 0.1210 - factorized_top_k/top_50_categorical_accuracy: 0.2702 - factorized_top_k/top_100_categorical_accuracy: 0.3613 - loss: 26061.7089 - regularization_loss: 0.0000e+00 - total_loss: 26061.7089\n",
      "Epoch 8/15\n",
      "79/79 [==============================] - 155s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0187 - factorized_top_k/top_5_categorical_accuracy: 0.0825 - factorized_top_k/top_10_categorical_accuracy: 0.1298 - factorized_top_k/top_50_categorical_accuracy: 0.2970 - factorized_top_k/top_100_categorical_accuracy: 0.3939 - loss: 25276.3946 - regularization_loss: 0.0000e+00 - total_loss: 25276.3946\n",
      "Epoch 9/15\n",
      "79/79 [==============================] - 156s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0160 - factorized_top_k/top_5_categorical_accuracy: 0.0795 - factorized_top_k/top_10_categorical_accuracy: 0.1289 - factorized_top_k/top_50_categorical_accuracy: 0.3095 - factorized_top_k/top_100_categorical_accuracy: 0.4141 - loss: 24656.3346 - regularization_loss: 0.0000e+00 - total_loss: 24656.3346\n",
      "Epoch 10/15\n",
      "79/79 [==============================] - 156s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0129 - factorized_top_k/top_5_categorical_accuracy: 0.0760 - factorized_top_k/top_10_categorical_accuracy: 0.1270 - factorized_top_k/top_50_categorical_accuracy: 0.3191 - factorized_top_k/top_100_categorical_accuracy: 0.4302 - loss: 24168.7096 - regularization_loss: 0.0000e+00 - total_loss: 24168.7096\n",
      "Epoch 11/15\n",
      "79/79 [==============================] - 155s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0107 - factorized_top_k/top_5_categorical_accuracy: 0.0720 - factorized_top_k/top_10_categorical_accuracy: 0.1231 - factorized_top_k/top_50_categorical_accuracy: 0.3233 - factorized_top_k/top_100_categorical_accuracy: 0.4405 - loss: 23812.5198 - regularization_loss: 0.0000e+00 - total_loss: 23812.5198\n",
      "Epoch 12/15\n",
      "79/79 [==============================] - 160s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0082 - factorized_top_k/top_5_categorical_accuracy: 0.0693 - factorized_top_k/top_10_categorical_accuracy: 0.1207 - factorized_top_k/top_50_categorical_accuracy: 0.3274 - factorized_top_k/top_100_categorical_accuracy: 0.4481 - loss: 23577.4236 - regularization_loss: 0.0000e+00 - total_loss: 23577.4236\n",
      "Epoch 13/15\n",
      "79/79 [==============================] - 154s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0058 - factorized_top_k/top_5_categorical_accuracy: 0.0675 - factorized_top_k/top_10_categorical_accuracy: 0.1192 - factorized_top_k/top_50_categorical_accuracy: 0.3299 - factorized_top_k/top_100_categorical_accuracy: 0.4531 - loss: 23453.0144 - regularization_loss: 0.0000e+00 - total_loss: 23453.0144\n",
      "Epoch 14/15\n",
      "79/79 [==============================] - 154s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0053 - factorized_top_k/top_5_categorical_accuracy: 0.0672 - factorized_top_k/top_10_categorical_accuracy: 0.1195 - factorized_top_k/top_50_categorical_accuracy: 0.3320 - factorized_top_k/top_100_categorical_accuracy: 0.4561 - loss: 23394.9562 - regularization_loss: 0.0000e+00 - total_loss: 23394.9562\n",
      "Epoch 15/15\n",
      "79/79 [==============================] - 154s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0098 - factorized_top_k/top_5_categorical_accuracy: 0.0695 - factorized_top_k/top_10_categorical_accuracy: 0.1213 - factorized_top_k/top_50_categorical_accuracy: 0.3335 - factorized_top_k/top_100_categorical_accuracy: 0.4576 - loss: 23371.7043 - regularization_loss: 0.0000e+00 - total_loss: 23371.7043\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1389a1490>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = BookBXModel(user_model, book_model, task)\n",
    "\n",
    "epochs = 15\n",
    "#cosine schedule\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=0.05,\n",
    "            decay_steps=epochs * len(ds_ratings_with_title) // 4096,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ds_ratings_with_title.batch(4096), epochs=epochs)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# divide dataset into train and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def train_model(train, test, model, epochs, batch_size, lr=0.01, cosine_decay=False):\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            tf.keras.optimizers.schedules.CosineDecay(\n",
    "                initial_learning_rate=lr,\n",
    "                decay_steps=epochs * len(train) // batch_size,\n",
    "            ) if cosine_decay\n",
    "\n",
    "            else lr\n",
    "        )\n",
    "    )\n",
    "    model.fit(train.batch(batch_size),  # todo forgot to shuffle\n",
    "              validation_data=test.batch(batch_size),\n",
    "              epochs=epochs,\n",
    "                callbacks=[tensorboard_callback]\n",
    "              )\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from dataset import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "63/63 [==============================] - 146s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0151 - factorized_top_k/top_5_categorical_accuracy: 0.0957 - factorized_top_k/top_10_categorical_accuracy: 0.1513 - factorized_top_k/top_50_categorical_accuracy: 0.3074 - factorized_top_k/top_100_categorical_accuracy: 0.3924 - loss: 26511.7045 - regularization_loss: 0.0000e+00 - total_loss: 26511.7045 - val_factorized_top_k/top_1_categorical_accuracy: 9.3897e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0030 - val_factorized_top_k/top_10_categorical_accuracy: 0.0088 - val_factorized_top_k/top_50_categorical_accuracy: 0.0572 - val_factorized_top_k/top_100_categorical_accuracy: 0.1033 - val_loss: 20606.7852 - val_regularization_loss: 0.0000e+00 - val_total_loss: 20606.7852\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 144s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0116 - factorized_top_k/top_5_categorical_accuracy: 0.1113 - factorized_top_k/top_10_categorical_accuracy: 0.1909 - factorized_top_k/top_50_categorical_accuracy: 0.3763 - factorized_top_k/top_100_categorical_accuracy: 0.4639 - loss: 24593.4319 - regularization_loss: 0.0000e+00 - total_loss: 24593.4319 - val_factorized_top_k/top_1_categorical_accuracy: 6.2598e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0023 - val_factorized_top_k/top_10_categorical_accuracy: 0.0081 - val_factorized_top_k/top_50_categorical_accuracy: 0.0573 - val_factorized_top_k/top_100_categorical_accuracy: 0.1060 - val_loss: 20653.0391 - val_regularization_loss: 0.0000e+00 - val_total_loss: 20653.0391\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 146s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0096 - factorized_top_k/top_5_categorical_accuracy: 0.1162 - factorized_top_k/top_10_categorical_accuracy: 0.2105 - factorized_top_k/top_50_categorical_accuracy: 0.4079 - factorized_top_k/top_100_categorical_accuracy: 0.4949 - loss: 23784.3173 - regularization_loss: 0.0000e+00 - total_loss: 23784.3173 - val_factorized_top_k/top_1_categorical_accuracy: 4.6948e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0018 - val_factorized_top_k/top_10_categorical_accuracy: 0.0075 - val_factorized_top_k/top_50_categorical_accuracy: 0.0572 - val_factorized_top_k/top_100_categorical_accuracy: 0.1067 - val_loss: 20856.4180 - val_regularization_loss: 0.0000e+00 - val_total_loss: 20856.4180\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 156s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0089 - factorized_top_k/top_5_categorical_accuracy: 0.1202 - factorized_top_k/top_10_categorical_accuracy: 0.2247 - factorized_top_k/top_50_categorical_accuracy: 0.4291 - factorized_top_k/top_100_categorical_accuracy: 0.5160 - loss: 23255.7270 - regularization_loss: 0.0000e+00 - total_loss: 23255.7270 - val_factorized_top_k/top_1_categorical_accuracy: 4.6948e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0016 - val_factorized_top_k/top_10_categorical_accuracy: 0.0070 - val_factorized_top_k/top_50_categorical_accuracy: 0.0563 - val_factorized_top_k/top_100_categorical_accuracy: 0.1063 - val_loss: 21095.4062 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21095.4062\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 133s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0084 - factorized_top_k/top_5_categorical_accuracy: 0.1240 - factorized_top_k/top_10_categorical_accuracy: 0.2349 - factorized_top_k/top_50_categorical_accuracy: 0.4445 - factorized_top_k/top_100_categorical_accuracy: 0.5312 - loss: 22861.8545 - regularization_loss: 0.0000e+00 - total_loss: 22861.8545 - val_factorized_top_k/top_1_categorical_accuracy: 4.6948e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0014 - val_factorized_top_k/top_10_categorical_accuracy: 0.0070 - val_factorized_top_k/top_50_categorical_accuracy: 0.0553 - val_factorized_top_k/top_100_categorical_accuracy: 0.1056 - val_loss: 21322.6211 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21322.6211\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 135s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0080 - factorized_top_k/top_5_categorical_accuracy: 0.1286 - factorized_top_k/top_10_categorical_accuracy: 0.2437 - factorized_top_k/top_50_categorical_accuracy: 0.4570 - factorized_top_k/top_100_categorical_accuracy: 0.5436 - loss: 22540.8139 - regularization_loss: 0.0000e+00 - total_loss: 22540.8139 - val_factorized_top_k/top_1_categorical_accuracy: 3.1299e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0014 - val_factorized_top_k/top_10_categorical_accuracy: 0.0064 - val_factorized_top_k/top_50_categorical_accuracy: 0.0549 - val_factorized_top_k/top_100_categorical_accuracy: 0.1050 - val_loss: 21527.3945 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21527.3945\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 141s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0082 - factorized_top_k/top_5_categorical_accuracy: 0.1342 - factorized_top_k/top_10_categorical_accuracy: 0.2515 - factorized_top_k/top_50_categorical_accuracy: 0.4669 - factorized_top_k/top_100_categorical_accuracy: 0.5538 - loss: 22265.2476 - regularization_loss: 0.0000e+00 - total_loss: 22265.2476 - val_factorized_top_k/top_1_categorical_accuracy: 3.1299e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0013 - val_factorized_top_k/top_10_categorical_accuracy: 0.0062 - val_factorized_top_k/top_50_categorical_accuracy: 0.0541 - val_factorized_top_k/top_100_categorical_accuracy: 0.1043 - val_loss: 21703.0977 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21703.0977\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 138s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0085 - factorized_top_k/top_5_categorical_accuracy: 0.1399 - factorized_top_k/top_10_categorical_accuracy: 0.2589 - factorized_top_k/top_50_categorical_accuracy: 0.4755 - factorized_top_k/top_100_categorical_accuracy: 0.5624 - loss: 22025.0343 - regularization_loss: 0.0000e+00 - total_loss: 22025.0343 - val_factorized_top_k/top_1_categorical_accuracy: 7.8247e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0012 - val_factorized_top_k/top_10_categorical_accuracy: 0.0061 - val_factorized_top_k/top_50_categorical_accuracy: 0.0534 - val_factorized_top_k/top_100_categorical_accuracy: 0.1037 - val_loss: 21851.8320 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21851.8320\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 133s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0085 - factorized_top_k/top_5_categorical_accuracy: 0.1456 - factorized_top_k/top_10_categorical_accuracy: 0.2653 - factorized_top_k/top_50_categorical_accuracy: 0.4830 - factorized_top_k/top_100_categorical_accuracy: 0.5697 - loss: 21816.2442 - regularization_loss: 0.0000e+00 - total_loss: 21816.2442 - val_factorized_top_k/top_1_categorical_accuracy: 7.8247e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0011 - val_factorized_top_k/top_10_categorical_accuracy: 0.0059 - val_factorized_top_k/top_50_categorical_accuracy: 0.0533 - val_factorized_top_k/top_100_categorical_accuracy: 0.1031 - val_loss: 21969.8555 - val_regularization_loss: 0.0000e+00 - val_total_loss: 21969.8555\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 142s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0088 - factorized_top_k/top_5_categorical_accuracy: 0.1522 - factorized_top_k/top_10_categorical_accuracy: 0.2718 - factorized_top_k/top_50_categorical_accuracy: 0.4890 - factorized_top_k/top_100_categorical_accuracy: 0.5759 - loss: 21639.0235 - regularization_loss: 0.0000e+00 - total_loss: 21639.0235 - val_factorized_top_k/top_1_categorical_accuracy: 6.2598e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0012 - val_factorized_top_k/top_10_categorical_accuracy: 0.0056 - val_factorized_top_k/top_50_categorical_accuracy: 0.0531 - val_factorized_top_k/top_100_categorical_accuracy: 0.1032 - val_loss: 22060.4414 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22060.4414\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 147s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0090 - factorized_top_k/top_5_categorical_accuracy: 0.1578 - factorized_top_k/top_10_categorical_accuracy: 0.2769 - factorized_top_k/top_50_categorical_accuracy: 0.4940 - factorized_top_k/top_100_categorical_accuracy: 0.5804 - loss: 21493.8399 - regularization_loss: 0.0000e+00 - total_loss: 21493.8399 - val_factorized_top_k/top_1_categorical_accuracy: 3.1299e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0011 - val_factorized_top_k/top_10_categorical_accuracy: 0.0057 - val_factorized_top_k/top_50_categorical_accuracy: 0.0526 - val_factorized_top_k/top_100_categorical_accuracy: 0.1030 - val_loss: 22124.0195 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22124.0195\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 122s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0092 - factorized_top_k/top_5_categorical_accuracy: 0.1622 - factorized_top_k/top_10_categorical_accuracy: 0.2812 - factorized_top_k/top_50_categorical_accuracy: 0.4975 - factorized_top_k/top_100_categorical_accuracy: 0.5838 - loss: 21381.0468 - regularization_loss: 0.0000e+00 - total_loss: 21381.0468 - val_factorized_top_k/top_1_categorical_accuracy: 4.6948e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0011 - val_factorized_top_k/top_10_categorical_accuracy: 0.0056 - val_factorized_top_k/top_50_categorical_accuracy: 0.0528 - val_factorized_top_k/top_100_categorical_accuracy: 0.1027 - val_loss: 22164.0898 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22164.0898\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 123s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0092 - factorized_top_k/top_5_categorical_accuracy: 0.1665 - factorized_top_k/top_10_categorical_accuracy: 0.2844 - factorized_top_k/top_50_categorical_accuracy: 0.5002 - factorized_top_k/top_100_categorical_accuracy: 0.5864 - loss: 21300.0754 - regularization_loss: 0.0000e+00 - total_loss: 21300.0754 - val_factorized_top_k/top_1_categorical_accuracy: 9.3897e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0010 - val_factorized_top_k/top_10_categorical_accuracy: 0.0057 - val_factorized_top_k/top_50_categorical_accuracy: 0.0526 - val_factorized_top_k/top_100_categorical_accuracy: 0.1025 - val_loss: 22184.9609 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22184.9609\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 120s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0095 - factorized_top_k/top_5_categorical_accuracy: 0.1691 - factorized_top_k/top_10_categorical_accuracy: 0.2867 - factorized_top_k/top_50_categorical_accuracy: 0.5018 - factorized_top_k/top_100_categorical_accuracy: 0.5878 - loss: 21249.3238 - regularization_loss: 0.0000e+00 - total_loss: 21249.3238 - val_factorized_top_k/top_1_categorical_accuracy: 3.1299e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0011 - val_factorized_top_k/top_10_categorical_accuracy: 0.0056 - val_factorized_top_k/top_50_categorical_accuracy: 0.0528 - val_factorized_top_k/top_100_categorical_accuracy: 0.1026 - val_loss: 22192.3750 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22192.3750\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 125s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0122 - factorized_top_k/top_5_categorical_accuracy: 0.1725 - factorized_top_k/top_10_categorical_accuracy: 0.2888 - factorized_top_k/top_50_categorical_accuracy: 0.5028 - factorized_top_k/top_100_categorical_accuracy: 0.5884 - loss: 21226.0631 - regularization_loss: 0.0000e+00 - total_loss: 21226.0631 - val_factorized_top_k/top_1_categorical_accuracy: 3.1299e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0011 - val_factorized_top_k/top_10_categorical_accuracy: 0.0057 - val_factorized_top_k/top_50_categorical_accuracy: 0.0526 - val_factorized_top_k/top_100_categorical_accuracy: 0.1025 - val_loss: 22193.1562 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22193.1562\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x13aad1c90>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = BookBXModel(user_model, book_model, task)\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 4096\n",
    "#cosine schedule\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=0.01,\n",
    "            decay_steps=epochs * len(train) // batch_size,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "model.fit(train.batch(batch_size),\n",
    "          validation_data=test.batch(batch_size),\n",
    "          epochs=epochs)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'dataset' from '/Users/adam/datasentics-uloha/dataset.py'>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset\n",
    "import importlib\n",
    "importlib.reload(dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "ratings_with_title_user_less_200 = filter_ratings(ratings_with_title, user_ratings_max_count=200)\n",
    "from dataset import squash_user_ids\n",
    "new_to_orig_user_id, orig_to_new_user_id = squash_user_ids(ratings_with_title_user_less_200)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "224170"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_with_title_user_less_200)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "44/44 [==============================] - 102s 2s/step - factorized_top_k/top_1_categorical_accuracy: 1.2267e-04 - factorized_top_k/top_5_categorical_accuracy: 9.8697e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0024 - factorized_top_k/top_50_categorical_accuracy: 0.0129 - factorized_top_k/top_100_categorical_accuracy: 0.0268 - loss: 53310.5327 - regularization_loss: 0.0000e+00 - total_loss: 53310.5327 - val_factorized_top_k/top_1_categorical_accuracy: 1.7844e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0013 - val_factorized_top_k/top_10_categorical_accuracy: 0.0030 - val_factorized_top_k/top_50_categorical_accuracy: 0.0157 - val_factorized_top_k/top_100_categorical_accuracy: 0.0321 - val_loss: 44607.2617 - val_regularization_loss: 0.0000e+00 - val_total_loss: 44607.2617\n",
      "Epoch 2/15\n",
      "44/44 [==============================] - 84s 2s/step - factorized_top_k/top_1_categorical_accuracy: 4.9070e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0043 - factorized_top_k/top_10_categorical_accuracy: 0.0088 - factorized_top_k/top_50_categorical_accuracy: 0.0377 - factorized_top_k/top_100_categorical_accuracy: 0.0694 - loss: 40477.0661 - regularization_loss: 0.0000e+00 - total_loss: 40477.0661 - val_factorized_top_k/top_1_categorical_accuracy: 3.1226e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0023 - val_factorized_top_k/top_10_categorical_accuracy: 0.0053 - val_factorized_top_k/top_50_categorical_accuracy: 0.0264 - val_factorized_top_k/top_100_categorical_accuracy: 0.0516 - val_loss: 38786.1602 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38786.1602\n",
      "Epoch 3/15\n",
      "44/44 [==============================] - 82s 2s/step - factorized_top_k/top_1_categorical_accuracy: 9.8697e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0126 - factorized_top_k/top_10_categorical_accuracy: 0.0237 - factorized_top_k/top_50_categorical_accuracy: 0.0817 - factorized_top_k/top_100_categorical_accuracy: 0.1354 - loss: 34551.3752 - regularization_loss: 0.0000e+00 - total_loss: 34551.3752 - val_factorized_top_k/top_1_categorical_accuracy: 4.2379e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0036 - val_factorized_top_k/top_10_categorical_accuracy: 0.0075 - val_factorized_top_k/top_50_categorical_accuracy: 0.0364 - val_factorized_top_k/top_100_categorical_accuracy: 0.0679 - val_loss: 36091.4805 - val_regularization_loss: 0.0000e+00 - val_total_loss: 36091.4805\n",
      "Epoch 4/15\n",
      "44/44 [==============================] - 83s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0250 - factorized_top_k/top_10_categorical_accuracy: 0.0457 - factorized_top_k/top_50_categorical_accuracy: 0.1367 - factorized_top_k/top_100_categorical_accuracy: 0.2091 - loss: 31153.3531 - regularization_loss: 0.0000e+00 - total_loss: 31153.3531 - val_factorized_top_k/top_1_categorical_accuracy: 4.9070e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0037 - val_factorized_top_k/top_10_categorical_accuracy: 0.0082 - val_factorized_top_k/top_50_categorical_accuracy: 0.0433 - val_factorized_top_k/top_100_categorical_accuracy: 0.0800 - val_loss: 34748.1289 - val_regularization_loss: 0.0000e+00 - val_total_loss: 34748.1289\n",
      "Epoch 5/15\n",
      "44/44 [==============================] - 83s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0018 - factorized_top_k/top_5_categorical_accuracy: 0.0406 - factorized_top_k/top_10_categorical_accuracy: 0.0714 - factorized_top_k/top_50_categorical_accuracy: 0.1929 - factorized_top_k/top_100_categorical_accuracy: 0.2796 - loss: 28966.4709 - regularization_loss: 0.0000e+00 - total_loss: 28966.4709 - val_factorized_top_k/top_1_categorical_accuracy: 3.7918e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0035 - val_factorized_top_k/top_10_categorical_accuracy: 0.0085 - val_factorized_top_k/top_50_categorical_accuracy: 0.0498 - val_factorized_top_k/top_100_categorical_accuracy: 0.0900 - val_loss: 34077.8047 - val_regularization_loss: 0.0000e+00 - val_total_loss: 34077.8047\n",
      "Epoch 6/15\n",
      "44/44 [==============================] - 82s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0023 - factorized_top_k/top_5_categorical_accuracy: 0.0569 - factorized_top_k/top_10_categorical_accuracy: 0.0974 - factorized_top_k/top_50_categorical_accuracy: 0.2448 - factorized_top_k/top_100_categorical_accuracy: 0.3406 - loss: 27445.4735 - regularization_loss: 0.0000e+00 - total_loss: 27445.4735 - val_factorized_top_k/top_1_categorical_accuracy: 2.6765e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0033 - val_factorized_top_k/top_10_categorical_accuracy: 0.0087 - val_factorized_top_k/top_50_categorical_accuracy: 0.0535 - val_factorized_top_k/top_100_categorical_accuracy: 0.0971 - val_loss: 33763.0977 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33763.0977\n",
      "Epoch 7/15\n",
      "44/44 [==============================] - 86s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0723 - factorized_top_k/top_10_categorical_accuracy: 0.1220 - factorized_top_k/top_50_categorical_accuracy: 0.2888 - factorized_top_k/top_100_categorical_accuracy: 0.3904 - loss: 26335.0242 - regularization_loss: 0.0000e+00 - total_loss: 26335.0242 - val_factorized_top_k/top_1_categorical_accuracy: 2.4535e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0030 - val_factorized_top_k/top_10_categorical_accuracy: 0.0088 - val_factorized_top_k/top_50_categorical_accuracy: 0.0556 - val_factorized_top_k/top_100_categorical_accuracy: 0.1027 - val_loss: 33634.7422 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33634.7422\n",
      "Epoch 8/15\n",
      "44/44 [==============================] - 99s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0038 - factorized_top_k/top_5_categorical_accuracy: 0.0866 - factorized_top_k/top_10_categorical_accuracy: 0.1438 - factorized_top_k/top_50_categorical_accuracy: 0.3252 - factorized_top_k/top_100_categorical_accuracy: 0.4301 - loss: 25503.6050 - regularization_loss: 0.0000e+00 - total_loss: 25503.6050 - val_factorized_top_k/top_1_categorical_accuracy: 1.1152e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0028 - val_factorized_top_k/top_10_categorical_accuracy: 0.0085 - val_factorized_top_k/top_50_categorical_accuracy: 0.0570 - val_factorized_top_k/top_100_categorical_accuracy: 0.1061 - val_loss: 33605.4883 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33605.4883\n",
      "Epoch 9/15\n",
      "44/44 [==============================] - 94s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0044 - factorized_top_k/top_5_categorical_accuracy: 0.0985 - factorized_top_k/top_10_categorical_accuracy: 0.1620 - factorized_top_k/top_50_categorical_accuracy: 0.3540 - factorized_top_k/top_100_categorical_accuracy: 0.4607 - loss: 24876.5214 - regularization_loss: 0.0000e+00 - total_loss: 24876.5214 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0025 - val_factorized_top_k/top_10_categorical_accuracy: 0.0084 - val_factorized_top_k/top_50_categorical_accuracy: 0.0588 - val_factorized_top_k/top_100_categorical_accuracy: 0.1089 - val_loss: 33623.4766 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33623.4766\n",
      "Epoch 10/15\n",
      " 6/44 [===>..........................] - ETA: 1:06 - factorized_top_k/top_1_categorical_accuracy: 0.0049 - factorized_top_k/top_5_categorical_accuracy: 0.1163 - factorized_top_k/top_10_categorical_accuracy: 0.1860 - factorized_top_k/top_50_categorical_accuracy: 0.3861 - factorized_top_k/top_100_categorical_accuracy: 0.4936 - loss: 24409.3802 - regularization_loss: 0.0000e+00 - total_loss: 24409.3802"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[81], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mratings_with_title_user_less_200\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBook-Title\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUser-ID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4096\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[47], line 12\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train, test, model, epochs, batch_size, lr)\u001B[0m\n\u001B[1;32m      2\u001B[0m tensorboard_callback \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mTensorBoard(log_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      5\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(\n\u001B[1;32m      6\u001B[0m         tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mschedules\u001B[38;5;241m.\u001B[39mCosineDecay(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     )\n\u001B[1;32m     11\u001B[0m )\n\u001B[0;32m---> 12\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m          \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/engine/training.py:1685\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1678\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1679\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1683\u001B[0m ):\n\u001B[1;32m   1684\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1685\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1687\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    891\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 894\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    896\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    897\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    923\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    924\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    925\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 926\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    927\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    928\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    929\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    930\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    141\u001B[0m   (concrete_function,\n\u001B[1;32m    142\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1753\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1755\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1756\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1757\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1758\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1759\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1760\u001B[0m     args,\n\u001B[1;32m   1761\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1762\u001B[0m     executing_eagerly)\n\u001B[1;32m   1763\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    380\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 381\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    387\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    388\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    389\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    390\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    393\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    394\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_model(*train_test_split(ratings_with_title_user_less_200[['Book-Title', 'User-ID']]), model, epochs=15, batch_size=4096, lr=0.01, cosine_decay=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "90/90 [==============================] - 114s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.1013 - factorized_top_k/top_10_categorical_accuracy: 0.1688 - factorized_top_k/top_50_categorical_accuracy: 0.3702 - factorized_top_k/top_100_categorical_accuracy: 0.4780 - loss: 10646.3035 - regularization_loss: 0.0000e+00 - total_loss: 10646.3035 - val_factorized_top_k/top_1_categorical_accuracy: 2.0074e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0023 - val_factorized_top_k/top_10_categorical_accuracy: 0.0086 - val_factorized_top_k/top_50_categorical_accuracy: 0.0603 - val_factorized_top_k/top_100_categorical_accuracy: 0.1119 - val_loss: 33649.0703 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33649.0703\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 98s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.1114 - factorized_top_k/top_10_categorical_accuracy: 0.1840 - factorized_top_k/top_50_categorical_accuracy: 0.3939 - factorized_top_k/top_100_categorical_accuracy: 0.5024 - loss: 10395.7519 - regularization_loss: 0.0000e+00 - total_loss: 10395.7519 - val_factorized_top_k/top_1_categorical_accuracy: 1.3383e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0020 - val_factorized_top_k/top_10_categorical_accuracy: 0.0084 - val_factorized_top_k/top_50_categorical_accuracy: 0.0618 - val_factorized_top_k/top_100_categorical_accuracy: 0.1144 - val_loss: 33705.7891 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33705.7891\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 102s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.1185 - factorized_top_k/top_10_categorical_accuracy: 0.1955 - factorized_top_k/top_50_categorical_accuracy: 0.4124 - factorized_top_k/top_100_categorical_accuracy: 0.5213 - loss: 10203.4621 - regularization_loss: 0.0000e+00 - total_loss: 10203.4621 - val_factorized_top_k/top_1_categorical_accuracy: 4.4609e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0022 - val_factorized_top_k/top_10_categorical_accuracy: 0.0080 - val_factorized_top_k/top_50_categorical_accuracy: 0.0626 - val_factorized_top_k/top_100_categorical_accuracy: 0.1167 - val_loss: 33794.2930 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33794.2930\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 101s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.1247 - factorized_top_k/top_10_categorical_accuracy: 0.2066 - factorized_top_k/top_50_categorical_accuracy: 0.4298 - factorized_top_k/top_100_categorical_accuracy: 0.5388 - loss: 10026.4687 - regularization_loss: 0.0000e+00 - total_loss: 10026.4687 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0020 - val_factorized_top_k/top_10_categorical_accuracy: 0.0079 - val_factorized_top_k/top_50_categorical_accuracy: 0.0628 - val_factorized_top_k/top_100_categorical_accuracy: 0.1179 - val_loss: 33904.0938 - val_regularization_loss: 0.0000e+00 - val_total_loss: 33904.0938\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 94s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.1305 - factorized_top_k/top_10_categorical_accuracy: 0.2166 - factorized_top_k/top_50_categorical_accuracy: 0.4460 - factorized_top_k/top_100_categorical_accuracy: 0.5552 - loss: 9863.3799 - regularization_loss: 0.0000e+00 - total_loss: 9863.3799 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0021 - val_factorized_top_k/top_10_categorical_accuracy: 0.0081 - val_factorized_top_k/top_50_categorical_accuracy: 0.0634 - val_factorized_top_k/top_100_categorical_accuracy: 0.1194 - val_loss: 34034.2539 - val_regularization_loss: 0.0000e+00 - val_total_loss: 34034.2539\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 97s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.1367 - factorized_top_k/top_10_categorical_accuracy: 0.2264 - factorized_top_k/top_50_categorical_accuracy: 0.4609 - factorized_top_k/top_100_categorical_accuracy: 0.5702 - loss: 9712.5644 - regularization_loss: 0.0000e+00 - total_loss: 9712.5644 - val_factorized_top_k/top_1_categorical_accuracy: 6.6914e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0022 - val_factorized_top_k/top_10_categorical_accuracy: 0.0077 - val_factorized_top_k/top_50_categorical_accuracy: 0.0638 - val_factorized_top_k/top_100_categorical_accuracy: 0.1206 - val_loss: 34178.1328 - val_regularization_loss: 0.0000e+00 - val_total_loss: 34178.1328\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 103s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0042 - factorized_top_k/top_5_categorical_accuracy: 0.1415 - factorized_top_k/top_10_categorical_accuracy: 0.2354 - factorized_top_k/top_50_categorical_accuracy: 0.4755 - factorized_top_k/top_100_categorical_accuracy: 0.5841 - loss: 9572.5653 - regularization_loss: 0.0000e+00 - total_loss: 9572.5653 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0020 - val_factorized_top_k/top_10_categorical_accuracy: 0.0077 - val_factorized_top_k/top_50_categorical_accuracy: 0.0638 - val_factorized_top_k/top_100_categorical_accuracy: 0.1210 - val_loss: 34335.6133 - val_regularization_loss: 0.0000e+00 - val_total_loss: 34335.6133\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 96s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0043 - factorized_top_k/top_5_categorical_accuracy: 0.1455 - factorized_top_k/top_10_categorical_accuracy: 0.2435 - factorized_top_k/top_50_categorical_accuracy: 0.4887 - factorized_top_k/top_100_categorical_accuracy: 0.5967 - loss: 9442.1633 - regularization_loss: 0.0000e+00 - total_loss: 9442.1633 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0020 - val_factorized_top_k/top_10_categorical_accuracy: 0.0077 - val_factorized_top_k/top_50_categorical_accuracy: 0.0641 - val_factorized_top_k/top_100_categorical_accuracy: 0.1221 - val_loss: 34503.0938 - val_regularization_loss: 0.0000e+00 - val_total_loss: 34503.0938\n",
      "Epoch 9/15\n",
      "34/90 [==========>...................] - ETA: 50s - factorized_top_k/top_1_categorical_accuracy: 0.0046 - factorized_top_k/top_5_categorical_accuracy: 0.1530 - factorized_top_k/top_10_categorical_accuracy: 0.2558 - factorized_top_k/top_50_categorical_accuracy: 0.5056 - factorized_top_k/top_100_categorical_accuracy: 0.6128 - loss: 9339.1848 - regularization_loss: 0.0000e+00 - total_loss: 9339.1848"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[83], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mratings_with_title_user_less_200\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBook-Title\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUser-ID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0025\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcosine_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[82], line 14\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train, test, model, epochs, batch_size, lr, cosine_decay)\u001B[0m\n\u001B[1;32m      2\u001B[0m tensorboard_callback \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mTensorBoard(log_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      5\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(\n\u001B[1;32m      6\u001B[0m         tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mschedules\u001B[38;5;241m.\u001B[39mCosineDecay(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     )\n\u001B[1;32m     13\u001B[0m )\n\u001B[0;32m---> 14\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m          \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/engine/training.py:1685\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1678\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1679\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1683\u001B[0m ):\n\u001B[1;32m   1684\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1685\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1687\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    891\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 894\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    896\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    897\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    923\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    924\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    925\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 926\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    927\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    928\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    929\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    930\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    141\u001B[0m   (concrete_function,\n\u001B[1;32m    142\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1753\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1755\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1756\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1757\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1758\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1759\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1760\u001B[0m     args,\n\u001B[1;32m   1761\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1762\u001B[0m     executing_eagerly)\n\u001B[1;32m   1763\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    380\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 381\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    387\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    388\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    389\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    390\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    393\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    394\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_model(*train_test_split(ratings_with_title_user_less_200[['Book-Title', 'User-ID']]), model, epochs=15, batch_size=2000, lr=0.0025, cosine_decay=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "90/90 [==============================] - 95s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0044 - factorized_top_k/top_5_categorical_accuracy: 0.1337 - factorized_top_k/top_10_categorical_accuracy: 0.2331 - factorized_top_k/top_50_categorical_accuracy: 0.4873 - factorized_top_k/top_100_categorical_accuracy: 0.5984 - loss: 9535.5077 - regularization_loss: 0.0000e+00 - total_loss: 9535.5077 - val_factorized_top_k/top_1_categorical_accuracy: 6.6914e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0018 - val_factorized_top_k/top_10_categorical_accuracy: 0.0076 - val_factorized_top_k/top_50_categorical_accuracy: 0.0642 - val_factorized_top_k/top_100_categorical_accuracy: 0.1225 - val_loss: 34926.2031 - val_regularization_loss: 0.0000e+00 - val_total_loss: 34926.2031\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 104s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0063 - factorized_top_k/top_5_categorical_accuracy: 0.1441 - factorized_top_k/top_10_categorical_accuracy: 0.2502 - factorized_top_k/top_50_categorical_accuracy: 0.5139 - factorized_top_k/top_100_categorical_accuracy: 0.6235 - loss: 9239.2656 - regularization_loss: 0.0000e+00 - total_loss: 9239.2656 - val_factorized_top_k/top_1_categorical_accuracy: 4.4609e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0019 - val_factorized_top_k/top_10_categorical_accuracy: 0.0074 - val_factorized_top_k/top_50_categorical_accuracy: 0.0642 - val_factorized_top_k/top_100_categorical_accuracy: 0.1226 - val_loss: 35267.9805 - val_regularization_loss: 0.0000e+00 - val_total_loss: 35267.9805\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 109s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0064 - factorized_top_k/top_5_categorical_accuracy: 0.1476 - factorized_top_k/top_10_categorical_accuracy: 0.2589 - factorized_top_k/top_50_categorical_accuracy: 0.5320 - factorized_top_k/top_100_categorical_accuracy: 0.6408 - loss: 9064.8892 - regularization_loss: 0.0000e+00 - total_loss: 9064.8892 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0019 - val_factorized_top_k/top_10_categorical_accuracy: 0.0075 - val_factorized_top_k/top_50_categorical_accuracy: 0.0640 - val_factorized_top_k/top_100_categorical_accuracy: 0.1228 - val_loss: 35643.4805 - val_regularization_loss: 0.0000e+00 - val_total_loss: 35643.4805\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 97s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0067 - factorized_top_k/top_5_categorical_accuracy: 0.1511 - factorized_top_k/top_10_categorical_accuracy: 0.2672 - factorized_top_k/top_50_categorical_accuracy: 0.5480 - factorized_top_k/top_100_categorical_accuracy: 0.6569 - loss: 8906.0678 - regularization_loss: 0.0000e+00 - total_loss: 8906.0678 - val_factorized_top_k/top_1_categorical_accuracy: 2.2305e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0017 - val_factorized_top_k/top_10_categorical_accuracy: 0.0072 - val_factorized_top_k/top_50_categorical_accuracy: 0.0635 - val_factorized_top_k/top_100_categorical_accuracy: 0.1227 - val_loss: 36026.4570 - val_regularization_loss: 0.0000e+00 - val_total_loss: 36026.4570\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 100s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0069 - factorized_top_k/top_5_categorical_accuracy: 0.1544 - factorized_top_k/top_10_categorical_accuracy: 0.2749 - factorized_top_k/top_50_categorical_accuracy: 0.5632 - factorized_top_k/top_100_categorical_accuracy: 0.6706 - loss: 8761.8759 - regularization_loss: 0.0000e+00 - total_loss: 8761.8759 - val_factorized_top_k/top_1_categorical_accuracy: 6.6914e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0017 - val_factorized_top_k/top_10_categorical_accuracy: 0.0071 - val_factorized_top_k/top_50_categorical_accuracy: 0.0633 - val_factorized_top_k/top_100_categorical_accuracy: 0.1226 - val_loss: 36421.4297 - val_regularization_loss: 0.0000e+00 - val_total_loss: 36421.4297\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 115s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0075 - factorized_top_k/top_5_categorical_accuracy: 0.1569 - factorized_top_k/top_10_categorical_accuracy: 0.2825 - factorized_top_k/top_50_categorical_accuracy: 0.5767 - factorized_top_k/top_100_categorical_accuracy: 0.6835 - loss: 8630.9515 - regularization_loss: 0.0000e+00 - total_loss: 8630.9515 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0015 - val_factorized_top_k/top_10_categorical_accuracy: 0.0068 - val_factorized_top_k/top_50_categorical_accuracy: 0.0625 - val_factorized_top_k/top_100_categorical_accuracy: 0.1229 - val_loss: 36815.7812 - val_regularization_loss: 0.0000e+00 - val_total_loss: 36815.7812\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 100s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0081 - factorized_top_k/top_5_categorical_accuracy: 0.1588 - factorized_top_k/top_10_categorical_accuracy: 0.2887 - factorized_top_k/top_50_categorical_accuracy: 0.5885 - factorized_top_k/top_100_categorical_accuracy: 0.6951 - loss: 8511.8205 - regularization_loss: 0.0000e+00 - total_loss: 8511.8205 - val_factorized_top_k/top_1_categorical_accuracy: 6.6914e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0013 - val_factorized_top_k/top_10_categorical_accuracy: 0.0064 - val_factorized_top_k/top_50_categorical_accuracy: 0.0617 - val_factorized_top_k/top_100_categorical_accuracy: 0.1231 - val_loss: 37213.5508 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37213.5508\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 112s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0084 - factorized_top_k/top_5_categorical_accuracy: 0.1605 - factorized_top_k/top_10_categorical_accuracy: 0.2944 - factorized_top_k/top_50_categorical_accuracy: 0.5996 - factorized_top_k/top_100_categorical_accuracy: 0.7059 - loss: 8403.2660 - regularization_loss: 0.0000e+00 - total_loss: 8403.2660 - val_factorized_top_k/top_1_categorical_accuracy: 4.4609e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0014 - val_factorized_top_k/top_10_categorical_accuracy: 0.0064 - val_factorized_top_k/top_50_categorical_accuracy: 0.0613 - val_factorized_top_k/top_100_categorical_accuracy: 0.1228 - val_loss: 37609.2461 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37609.2461\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 99s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0086 - factorized_top_k/top_5_categorical_accuracy: 0.1617 - factorized_top_k/top_10_categorical_accuracy: 0.2992 - factorized_top_k/top_50_categorical_accuracy: 0.6095 - factorized_top_k/top_100_categorical_accuracy: 0.7149 - loss: 8303.9545 - regularization_loss: 0.0000e+00 - total_loss: 8303.9545 - val_factorized_top_k/top_1_categorical_accuracy: 8.9218e-05 - val_factorized_top_k/top_5_categorical_accuracy: 0.0012 - val_factorized_top_k/top_10_categorical_accuracy: 0.0065 - val_factorized_top_k/top_50_categorical_accuracy: 0.0605 - val_factorized_top_k/top_100_categorical_accuracy: 0.1224 - val_loss: 38003.6602 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38003.6602\n",
      "Epoch 10/15\n",
      "90/90 [==============================] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 0.0090 - factorized_top_k/top_5_categorical_accuracy: 0.1628 - factorized_top_k/top_10_categorical_accuracy: 0.3035 - factorized_top_k/top_50_categorical_accuracy: 0.6184 - factorized_top_k/top_100_categorical_accuracy: 0.7234 - loss: 8247.5999 - regularization_loss: 0.0000e+00 - total_loss: 8247.5999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[84], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mratings_with_title_user_less_200\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBook-Title\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUser-ID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.005\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcosine_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[82], line 14\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train, test, model, epochs, batch_size, lr, cosine_decay)\u001B[0m\n\u001B[1;32m      2\u001B[0m tensorboard_callback \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mTensorBoard(log_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      5\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(\n\u001B[1;32m      6\u001B[0m         tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mschedules\u001B[38;5;241m.\u001B[39mCosineDecay(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     )\n\u001B[1;32m     13\u001B[0m )\n\u001B[0;32m---> 14\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m          \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/engine/training.py:1729\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1715\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[1;32m   1716\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m   1717\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1727\u001B[0m         steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution,\n\u001B[1;32m   1728\u001B[0m     )\n\u001B[0;32m-> 1729\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1730\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1731\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1732\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1733\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1734\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1735\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1741\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1742\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   1744\u001B[0m }\n\u001B[1;32m   1745\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/keras/engine/training.py:2072\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   2068\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   2069\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2070\u001B[0m ):\n\u001B[1;32m   2071\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 2072\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2073\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   2074\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    891\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 894\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    896\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    897\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    931\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    932\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[1;32m    935\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    936\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    141\u001B[0m   (concrete_function,\n\u001B[1;32m    142\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1753\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1755\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1756\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1757\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1758\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1759\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1760\u001B[0m     args,\n\u001B[1;32m   1761\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1762\u001B[0m     executing_eagerly)\n\u001B[1;32m   1763\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    380\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 381\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    387\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    388\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    389\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    390\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    393\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    394\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/venvs/datasentics-uloha/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_model(*train_test_split(ratings_with_title_user_less_200[['Book-Title', 'User-ID']]), model, epochs=15, batch_size=2000, lr=0.005, cosine_decay=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
